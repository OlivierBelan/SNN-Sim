[Runner_Info]
runner_type = Reinforcement


[NEURO_EVOLUTION]
verbose = True
# maximize, minimize or closest_to_zero
optimization_type = maximize
algo_name = NES-evosax

[Record]
criteria=best_episode_raw_score mean_episode_raw_score
sorted_by=best_episode_raw_score

[Genome_NN]
inputs = 27
hiddens = 64x64
hiddens_active = 128
outputs = 8
inputs_multiplicator = 1
hiddens_multiplicator = 1
outputs_multiplicator = 1

is_self_neuron_connection = True
# Hidden layer can be used as a feedback to another hidden layer, 
# e.g H1->H2 will considered as a feedback and forward connection
is_inter_hidden_feedback = False
is_layer_normalization = False

architecture = I->H1, H1->H2, H2->O
# architecture = I->H1, I->O, H1->H1, H1->O, O->H1, O->O
# architecture = I->I, I->H1, I->O, H1->I, H1->H1, H1->O, O->I, O->H1, O->O
# architecture = I->H1, I->H2, I->O, I->I, H1->O, H1->H1, H1->H2, H1->I, H2->O, H2->H1, H2->H2, H2->I, O->O, O->I, O->H1, O->H2
network_type = ANN


[NES-evosax]
pop_size = 128
verbose = False

sigma_init = 1.0
temperature = 0.0
mean_decay = 0.0



[weight_synapse_parameter]
max = 0.0
min = 0.0

mu = 0.0
mu_max = 0.0
mu_min = 0.0

sigma = 0.0
sigma_max = 0.0
sigma_min = 0.0
sigma_decay = 1.0

# [bias_neuron_parameter]
# max = 0.0
# min = 0.0

# mu = 0.0
# mu_max = 0.0
# mu_min = 0.0

# sigma = 0.0
# sigma_max = 0.0
# sigma_min = 0.0
# sigma_decay = 1.0
